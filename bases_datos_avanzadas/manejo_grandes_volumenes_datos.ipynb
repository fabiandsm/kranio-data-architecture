{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91933432",
   "metadata": {},
   "source": [
    "# Manejo de Grandes Volúmenes de Datos (Big Data Basics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae87a0b",
   "metadata": {},
   "source": [
    "## 0. Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e1af334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de volúmenes y patrones para e-commerce\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b443b02",
   "metadata": {},
   "source": [
    "## 1. Análisis de requisitos y patrones de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df576ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTIMACIONES DE VOLUMEN - E-COMMERCE MENSUAL\n",
      "==================================================\n",
      "eventos_usuario: 50000000\n",
      "ordenes: 1000000\n",
      "productos: 100000\n",
      "clientes_activos: 5000000\n",
      "reviews: 500000\n",
      "logs_sistema: 100000000\n",
      "\n",
      "PATRONES DE CONSULTA IDENTIFICADOS\n",
      "========================================\n",
      "\n",
      "TIEMPO_REAL:\n",
      " • ¿Cuántos usuarios activos ahora?\n",
      " • ¿Cuál es la conversión actual?\n",
      " • ¿Hay anomalías en ventas?\n",
      "\n",
      "BATCH_DIARIO:\n",
      " • Reportes de ventas por categoría\n",
      " • Análisis de comportamiento de cliente\n",
      " • Optimización de inventario\n",
      "\n",
      "BATCH_SEMANAL:\n",
      " • Tendencias de productos\n",
      " • Segmentación de clientes\n",
      " • Análisis de campañas de marketing\n"
     ]
    }
   ],
   "source": [
    "# Estimación de volúmenes para plataforma e-commerce\n",
    "estimaciones_mensuales = {\n",
    "    'eventos_usuario': 50000000,    # 50M eventos (clicks, views, etc.)\n",
    "    'ordenes': 1000000,             # 1M órdenes\n",
    "    'productos': 100000,            # 100K productos\n",
    "    'clientes_activos': 5000000,    # 5M clientes activos\n",
    "    'reviews': 500000,              # 500K reviews\n",
    "    'logs_sistema': 100000000       # 100M logs diarios\n",
    "}\n",
    "\n",
    "print(\"ESTIMACIONES DE VOLUMEN - E-COMMERCE MENSUAL\")\n",
    "print(\"=\" * 50)\n",
    "for componente, volumen in estimaciones_mensuales.items():\n",
    "    print(f\"{componente}: {volumen}\")\n",
    "\n",
    "# Patrones de consulta identificados\n",
    "patrones_consulta = {\n",
    "    'tiempo_real': [\n",
    "        '¿Cuántos usuarios activos ahora?',\n",
    "        '¿Cuál es la conversión actual?',\n",
    "        '¿Hay anomalías en ventas?'\n",
    "    ],\n",
    "    'batch_diario': [\n",
    "        'Reportes de ventas por categoría',\n",
    "        'Análisis de comportamiento de cliente',\n",
    "        'Optimización de inventario'\n",
    "    ],\n",
    "    'batch_semanal': [\n",
    "        'Tendencias de productos',\n",
    "        'Segmentación de clientes',\n",
    "        'Análisis de campañas de marketing'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\nPATRONES DE CONSULTA IDENTIFICADOS\")\n",
    "print(\"=\" * 40)\n",
    "for frecuencia, consultas in patrones_consulta.items():\n",
    "    print(f\"\\n{frecuencia.upper()}:\")\n",
    "    for consulta in consultas:\n",
    "        print(f\" • {consulta}\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb0fee",
   "metadata": {},
   "source": [
    "## 2.**Diseño de arquitectura híbrida Lambda**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb03bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARQUITECTURA LAMBDA PROPUESTA\n",
      "===================================\n",
      "\n",
      "CAPA STREAMING:\n",
      "  Tecnologías: Apache Kafka, Apache Flink, Redis\n",
      "  Latencia: milisegundos-segundos\n",
      "  Casos de uso:\n",
      "    • Monitoreo en tiempo real de ventas\n",
      "    • Detección de fraudes\n",
      "    • Personalización de recomendaciones\n",
      "    • Alertas de inventario bajo\n",
      "\n",
      "CAPA BATCH:\n",
      "  Tecnologías: Apache Spark, Hadoop MapReduce, Apache Airflow\n",
      "  Latencia: horas-días\n",
      "  Casos de uso:\n",
      "    • Reportes de performance mensual\n",
      "    • Modelos de machine learning\n",
      "    • Análisis de cohortes de clientes\n",
      "    • Optimización de precios\n",
      "\n",
      "CAPA SERVING:\n",
      "  Tecnologías: Apache Druid, ClickHouse, Elasticsearch\n",
      "  Funciones:\n",
      "    • Unificar resultados batch + streaming\n",
      "    • Servir consultas analíticas rápidas\n",
      "    • Dashboards en tiempo real\n",
      "    • APIs para aplicaciones\n"
     ]
    }
   ],
   "source": [
    "# Arquitectura Lambda para e-commerce\n",
    "arquitectura_lambda = {\n",
    "    'capa_streaming': {\n",
    "        'tecnologias': ['Apache Kafka', 'Apache Flink', 'Redis'],\n",
    "        'casos_uso': [\n",
    "            'Monitoreo en tiempo real de ventas',\n",
    "            'Detección de fraudes',\n",
    "            'Personalización de recomendaciones',\n",
    "            'Alertas de inventario bajo'\n",
    "        ],\n",
    "        'latencia': 'milisegundos-segundos',\n",
    "        'datos': 'eventos individuales'\n",
    "    },\n",
    "    'capa_batch': {\n",
    "        'tecnologias': ['Apache Spark', 'Hadoop MapReduce', 'Apache Airflow'],\n",
    "        'casos_uso': [\n",
    "            'Reportes de performance mensual',\n",
    "            'Modelos de machine learning',\n",
    "            'Análisis de cohortes de clientes',\n",
    "            'Optimización de precios'\n",
    "        ],\n",
    "        'latencia': 'horas-días',\n",
    "        'datos': 'datasets completos'\n",
    "    },\n",
    "    'capa_serving': {\n",
    "        'tecnologias': ['Apache Druid', 'ClickHouse', 'Elasticsearch'],\n",
    "        'funciones': [\n",
    "            'Unificar resultados batch + streaming',\n",
    "            'Servir consultas analíticas rápidas',\n",
    "            'Dashboards en tiempo real',\n",
    "            'APIs para aplicaciones'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ARQUITECTURA LAMBDA PROPUESTA\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "for capa, detalles in arquitectura_lambda.items():\n",
    "    print(f\"\\n{capa.upper().replace('_', ' ')}:\")\n",
    "    if detalles.get('tecnologias'):\n",
    "        print(f\"  Tecnologías: {', '.join(detalles['tecnologias'])}\")\n",
    "    if 'latencia' in detalles:\n",
    "        print(f\"  Latencia: {detalles['latencia']}\")\n",
    "    if 'casos_uso' in detalles:\n",
    "        print(\"  Casos de uso:\")\n",
    "        for caso in detalles['casos_uso']:\n",
    "            print(f\"    • {caso}\")\n",
    "    elif 'funciones' in detalles:\n",
    "        print(\"  Funciones:\")\n",
    "        for func in detalles['funciones']:\n",
    "            print(f\"    • {func}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f93e7",
   "metadata": {},
   "source": [
    "## 3. Estrategias de particionamiento y escalabilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "171ffec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL de particionamiento almacenado en sql_particionamiento\n"
     ]
    }
   ],
   "source": [
    "sql_particionamiento = \"\"\"\n",
    "-- Estrategias de particionamiento para diferentes componentes\n",
    "\n",
    "-- 1. Eventos de usuario (streaming + histórico)\n",
    "-- Kafka topics particionados por tipo de evento\n",
    "CREATE TABLE eventos_usuario (\n",
    "    timestamp TIMESTAMP,\n",
    "    user_id BIGINT,\n",
    "    event_type VARCHAR(50),\n",
    "    session_id VARCHAR(100),\n",
    "    properties JSONB,\n",
    "    -- Particionamiento por tiempo + hash para distribución\n",
    "    PARTITION BY RANGE (timestamp) SUBPARTITION BY HASH (user_id)\n",
    ");\n",
    "\n",
    "-- 2. Órdenes de compra (transaccional + analítico)\n",
    "CREATE TABLE ordenes (\n",
    "    order_id BIGINT PRIMARY KEY,\n",
    "    user_id BIGINT,\n",
    "    order_date TIMESTAMP,\n",
    "    total_amount DECIMAL(10,2),\n",
    "    status VARCHAR(20),\n",
    "    -- Particionamiento mensual para optimización temporal\n",
    "    PARTITION BY RANGE (EXTRACT(YEAR_MONTH FROM order_date))\n",
    ");\n",
    "\n",
    "-- 3. Datos de productos (relacional + búsqueda)\n",
    "-- Elasticsearch para búsqueda, PostgreSQL para datos maestros\n",
    "CREATE TABLE productos (\n",
    "    product_id BIGINT PRIMARY KEY,\n",
    "    category_id INTEGER,\n",
    "    name VARCHAR(200),\n",
    "    price DECIMAL(10,2),\n",
    "    stock_quantity INTEGER,\n",
    "    -- Índices para diferentes patrones de consulta\n",
    "    INDEX idx_category_price (category_id, price),\n",
    "    INDEX idx_name_fts (name) USING GIN,  -- Full-text search\n",
    "    INDEX idx_stock (stock_quantity) WHERE stock_quantity > 0\n",
    ");\n",
    "\n",
    "-- 4. Métricas agregadas (data warehouse columnar)\n",
    "-- ClickHouse para analytics de alto rendimiento\n",
    "CREATE TABLE metricas_diarias (\n",
    "    fecha DATE,\n",
    "    categoria VARCHAR(50),\n",
    "    region VARCHAR(50),\n",
    "    ventas_total DECIMAL(10,2),\n",
    "    ordenes_total INTEGER,\n",
    "    clientes_unicos INTEGER,\n",
    "    conversion_rate DECIMAL(5,4)\n",
    ") ENGINE = MergeTree()\n",
    "PARTITION BY toYYYYMM(fecha)\n",
    "ORDER BY (fecha, categoria, region);\n",
    "\"\"\"\n",
    "\n",
    "print(\"SQL de particionamiento almacenado en sql_particionamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf33403",
   "metadata": {},
   "source": [
    "## 4. Implementación de pipeline de procesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b858ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ESTRATEGIA DE ESCALABILIDAD\n",
      "==============================\n",
      "Volumen actual: 10TB datos/mes\n",
      "Proyección 2 años: 100TB datos/mes\n",
      "Estrategias:\n",
      " • Auto-scaling de clusters Spark/Flink\n",
      " • Particionamiento horizontal adicional\n",
      " • Compresión columnar avanzada\n",
      " • Cache distribuido (Redis Cluster)\n",
      " • CDN para datos estáticos\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de procesamiento para arquitectura Lambda\n",
    "def lambda_pipeline_arquitecture():\n",
    "    \"\"\"Arquitectura Lambda simplificada para e-commerce\"\"\"\n",
    "\n",
    "    # CAPA DE STREAMING (velocidad)\n",
    "    def capa_streaming():\n",
    "        \"\"\"Procesamiento en tiempo real\"\"\"\n",
    "        eventos_stream = kafka_consumer.consume('user_events')\n",
    "\n",
    "        # Procesamiento con Flink (pseudocódigo)\n",
    "        eventos_procesados = eventos_stream \\\n",
    "            .filter(lambda x: x['event_type'] == 'purchase') \\\n",
    "            .key_by(lambda x: x['user_id']) \\\n",
    "            .window(TumblingEventTimeWindows.of(Time.minutes(5))) \\\n",
    "            .aggregate(AggregationFunction())\n",
    "\n",
    "        # Resultados a Redis para consultas rápidas\n",
    "        eventos_procesados.addSink(redis_sink)\n",
    "\n",
    "        # También a storage duradero para batch layer\n",
    "        eventos_procesados.addSink(s3_sink)\n",
    "\n",
    "    # CAPA DE BATCH (precisión)\n",
    "    def capa_batch():\n",
    "        \"\"\"Procesamiento completo y preciso\"\"\"\n",
    "        datos_completos = spark.read.parquet('s3://data-lake/events/')\n",
    "\n",
    "        # Procesamiento completo con Spark\n",
    "        metricas_batch = datos_completos \\\n",
    "            .groupBy('fecha', 'categoria') \\\n",
    "            .agg(\n",
    "                sum('revenue').alias('ventas_total'),\n",
    "                countDistinct('user_id').alias('clientes_unicos'),\n",
    "                (sum('purchases') / countDistinct('user_id')).alias('conversion_rate')\n",
    "            )\n",
    "\n",
    "        # Guardar resultados batch\n",
    "        metricas_batch.write.mode('overwrite').parquet('s3://data-lake/batch-metrics/')\n",
    "\n",
    "    # CAPA DE SERVING (unificación)\n",
    "    def capa_serving():\n",
    "        \"\"\"Unificar y servir resultados\"\"\"\n",
    "        resultados_streaming = redis_cluster.get_recent_metrics()\n",
    "        resultados_batch = spark.read.parquet('s3://data-lake/batch-metrics/')\n",
    "\n",
    "        # Unificar en ClickHouse para consultas analíticas\n",
    "        resultados_combinados = merge_results(resultados_streaming, resultados_batch)\n",
    "        clickhouse_client.insert('metricas_unificadas', resultados_combinados)\n",
    "\n",
    "    return {\n",
    "        'streaming': capa_streaming,\n",
    "        'batch': capa_batch,\n",
    "        'serving': capa_serving\n",
    "    }\n",
    "\n",
    "# Demostración de escalabilidad\n",
    "escalabilidad = {\n",
    "    'volumen_actual': '10TB datos/mes',\n",
    "    'proyeccion_2_años': '100TB datos/mes',\n",
    "    'estrategias_escalabilidad': [\n",
    "        'Auto-scaling de clusters Spark/Flink',\n",
    "        'Particionamiento horizontal adicional',\n",
    "        'Compresión columnar avanzada',\n",
    "        'Cache distribuido (Redis Cluster)',\n",
    "        'CDN para datos estáticos'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\nESTRATEGIA DE ESCALABILIDAD\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Volumen actual: {escalabilidad['volumen_actual']}\")\n",
    "print(f\"Proyección 2 años: {escalabilidad['proyeccion_2_años']}\")\n",
    "print(\"Estrategias:\")\n",
    "for estrategia in escalabilidad['estrategias_escalabilidad']:\n",
    "    print(f\" • {estrategia}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7221b",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Verficación\n",
    "\n",
    "Explica cómo la arquitectura Lambda resuelve el trade-off entre velocidad (streaming) y precisión (batch).\n",
    "\n",
    "- La arquitectura Lambda divide el procesamiento de datos en dos caminos complementarios: la Batch Layer y la Speed Layer. Este enfoque reconoce que no es posible maximizar simultáneamente la velocidad de procesamiento y la exactitud de los resultados. Por ello, Lambda utiliza procesamiento streaming para ofrecer baja latencia y procesamiento batch para garantizar la precisión final, con esto se logra un equilibrio práctico entre ambos objetivos.\n",
    "\n",
    "**Batch Layer**: procesa el histórico completo de los datos con alta precisión, permitiendo la corrección de errores y el recálculo total de los resultados, asegurando una consistencia fuerte.\n",
    "\n",
    "**Speed Layer** (streaming): procesa los datos recientes en tiempo real, proporcionando resultados inmediatos, aunque potencialmente aproximados.\n",
    "\n",
    "**Serving Layer**: integra los resultados de ambas capas para entregar una vista unificada y consistente a los usuarios.\n",
    "\n",
    "**Conclusión**: La elección entre Lambda y Kappa depende de los requisitos de precisión, latencia y complejidad. Lambda es adecuada cuando se necesita combinar tiempo real y alta exactitud histórica, aceptando una arquitectura más compleja. Kappa, en cambio, es preferible cuando el streaming es suficiente y se busca una solución más simple, moderna y mantenible, reduciendo costos operativos y puntos de falla.\n",
    "\n",
    "Describe escenarios donde elegirías Kappa sobre Lambda para simplificar la arquitectura.\n",
    "\n",
    "- Elegiría Kappa cuando todo el procesamiento puede realizarse mediante streaming, que no sea necesario recalcular datos históricos completos con frecuencia y se busque reducir la complejidad operativa. En este enfoque, un log inmutable, como Apache Kafka, actúa como fuente única de verdad.\n",
    "\n",
    "Los casos típicos de uso:\n",
    "•\tMonitoreo en tiempo real\n",
    "•\tIoT\n",
    "•\tClickstream\n",
    "•\tSistemas de alertas\n",
    "\n",
    "**Conclusión**: Kappa elimina la duplicidad entre batch y streaming, reduciendo código, costos operativos y puntos de falla.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf9c56",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
